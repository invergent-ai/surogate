model: Qwen/Qwen3-0.6B
output_dir: ./output
merge_adapter: false
apply_recommended_values: false

per_device_train_batch_size: 8
gradient_accumulation_steps: 1

sample_packing: true
sequence_len: 2048
truncation_strategy: split
use_chat_template: false
loss_scale: all

num_epochs: 10
eval_steps: 100
save_steps: 0

learning_rate: 6e-4
lr_scheduler_type: cosine
final_lr_fraction: 0.1
warmup_steps: 10
max_grad_norm: 1.0

recipe: fp8-hybrid
optimizer: normuon
gpus: 4
lora: false

dataloader_num_workers: 48
datasets:
  - path: "HuggingFaceFW/fineweb-2"
    subset: ron_Latn
    split: train
    type: text
validation_datasets:
  - path: "HuggingFaceFW/fineweb-2"
    subset: ron_Latn
    split: test
    type: text
