import std.primitives.matmul
import std.primitives.activations
module SwiGLUMLP(
  d_model: int,
  d_ff: int
):
  """
  SwiGLU MLP: gate+up projection -> SwiGLU -> down projection.
  """
  let:
    C = d_model
    M = d_ff
    MUp = 2 * M
  params:
    up_weight: [MUp, C]
    down_weight: [C, M]
  forward:
    inputs:
      x: [B, T, C]
    outputs:
      y: [B, T, C]
    graph:
      x -> view(shape=[B * T, C]) -> x_flat
      (x_flat, up_weight) -> matmul(transpose=NT) -> up_flat
      up_flat -> view(shape=[B, T, MUp]) -> up
      up -> swiglu() -> act
      act -> view(shape=[B * T, M]) -> act_flat
      (act_flat, down_weight) -> matmul(transpose=NT) -> y_flat
      y_flat -> view(shape=[B, T, C]) -> y
