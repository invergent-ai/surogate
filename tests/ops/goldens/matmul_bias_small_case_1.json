{
  "attrs": {
    "transpose": "NN"
  },
  "case": "small_case_1",
  "grads": {
    "d_a": {
      "data": [
        6.0,
        -3.0,
        -1.5,
        -3.25,
        4.75,
        4.25
      ],
      "dtype": "fp64",
      "shape": [
        2,
        3
      ]
    },
    "d_b": {
      "data": [
        1.125,
        1.0,
        1.25,
        -0.75,
        1.75,
        -4.0,
        5.5,
        -2.5,
        -0.25,
        9.5,
        -6.5,
        2.5
      ],
      "dtype": "fp64",
      "shape": [
        3,
        4
      ]
    },
    "d_bias": {
      "data": [
        1.25,
        2.5,
        0.5,
        -0.5
      ],
      "dtype": "fp64",
      "shape": [
        4
      ]
    },
    "d_out": {
      "data": [
        1.0,
        -0.5,
        2.0,
        -1.0,
        0.25,
        3.0,
        -1.5,
        0.5
      ],
      "dtype": "fp64",
      "shape": [
        2,
        4
      ]
    }
  },
  "inputs": {
    "a": {
      "data": [
        1.0,
        2.0,
        -1.0,
        0.5,
        -1.0,
        3.0
      ],
      "dtype": "fp64",
      "shape": [
        2,
        3
      ]
    },
    "b": {
      "data": [
        1.0,
        0.0,
        2.0,
        -1.0,
        0.0,
        1.0,
        -1.0,
        0.5,
        1.0,
        1.0,
        0.0,
        2.0
      ],
      "dtype": "fp64",
      "shape": [
        3,
        4
      ]
    },
    "bias": {
      "data": [
        0.5,
        -1.0,
        2.0,
        -0.25
      ],
      "dtype": "fp64",
      "shape": [
        4
      ]
    }
  },
  "meta": {
    "note": "Matmul with bias added on last dimension."
  },
  "op": "matmul_bias",
  "outputs": {
    "out": {
      "data": [
        0.5,
        0.0,
        2.0,
        -2.25,
        4.0,
        1.0,
        4.0,
        4.75
      ],
      "dtype": "fp64",
      "shape": [
        2,
        4
      ]
    }
  }
}
